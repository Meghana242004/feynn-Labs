{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7920556,"sourceType":"datasetVersion","datasetId":4654433}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset from the downloaded CSV file\nmcdonalds_path = '../input/mcdonalds/mcdonalds.csv'\nmcdonalds = pd.read_csv(mcdonalds_path)\n\n# Display column names\nprint(mcdonalds.columns.tolist())\n\n# Display dimensions\nprint(mcdonalds.shape)\n\n# Display first 3 rows\nprint(mcdonalds.head(3))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Assuming you have already loaded the data into a pandas DataFrame named 'mcdonalds'\n# If not, load the data using pd.read_csv() or other appropriate functions\n\n# Select columns from 1 to 11 (indexing starts from 0 in Python)\nMD_x = mcdonalds.iloc[:, 0:11].copy()\n\n# Convert \"Yes\" to 1 and \"No\" to 0\nMD_x = (MD_x == \"Yes\").astype(int)\n\n# Calculate column means\ncolumn_means = np.round(MD_x.mean(), 2)\n\nprint(column_means)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\n# Assuming you have already defined MD_x and column_means as in the previous code snippet\n\n# Perform PCA\nMD_pca = PCA()\nMD_pca.fit(MD_x)\n\n# Display summary\nprint(\"Importance of components:\")\nprint(pd.DataFrame({\n    \"Standard deviation\": np.round(MD_pca.explained_variance_, 4),\n    \"Proportion of Variance\": np.round(MD_pca.explained_variance_ratio_, 4),\n    \"Cumulative Proportion\": np.round(np.cumsum(MD_pca.explained_variance_ratio_), 4)\n}))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you have already defined MD_pca as in the previous code snippet\n\n# Function to print PCA object with specified number of digits\ndef print_pca(pca_obj, digits):\n    print(\"Standard deviations (1, .., p={}):\".format(pca_obj.n_components_))\n    print(np.round(pca_obj.explained_variance_, digits))\n    print(\"Rotation (n x k) = ({} x {}):\".format(pca_obj.components_.shape[1], pca_obj.components_.shape[0]))\n    print(np.round(pca_obj.components_, digits))\n\n# Print PCA object with specified number of digits\nprint_pca(MD_pca, digits=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\n# Assuming you have already defined MD_x and MD_pca as in the previous code snippets\n\n# Perform PCA\nMD_pca = PCA()\nMD_pca.fit(MD_x)\n\n# Transform data using PCA\ntransformed_data = MD_pca.transform(MD_x)\n\n# Plot PCA\nplt.scatter(transformed_data[:, 0], transformed_data[:, 1], color='grey')\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.title(\"PCA Plot\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport numpy as np\n\n# Set random seed\nnp.random.seed(1234)\n\n# Assuming you have already defined MD_x as in the previous code snippets\n\n# Perform K-means clustering with 2 to 8 clusters\nk_values = range(2, 9)\nbest_model = None\nbest_score = float('inf')\n\nfor k in k_values:\n    model = KMeans(n_clusters=k, n_init=10, random_state=1234)\n    model.fit(MD_x)\n    if model.inertia_ < best_score:\n        best_model = model\n        best_score = model.inertia_\n\n# Relabel the clusters\ncluster_labels = best_model.labels_\n\n# Print cluster labels\nprint(cluster_labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Assuming you have already defined MD_x as in the previous code snippets\n\n# Fit K-means clustering with a chosen number of clusters\nk_values = range(2, 9)  # Choose the range of k values to try\ninertia_values = []\n\nfor k in k_values:\n    kmeans = KMeans(n_clusters=k, n_init=10, random_state=1234)\n    kmeans.fit(MD_x)\n    inertia_values.append(kmeans.inertia_)\n\n# Plot inertia (within-cluster sum of squares) vs. number of clusters\nplt.plot(k_values, inertia_values, marker='o')\nplt.xlabel(\"Number of Clusters (k)\")\nplt.ylabel(\"Inertia\")\nplt.title(\"Elbow Method to Choose Number of Clusters\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Assuming you have already defined MD_x as a DataFrame containing categorical variables\n\n# One-hot encode categorical variables\nencoder = OneHotEncoder(sparse_output=False, drop='first')  # Drop first category to avoid multicollinearity\nMD_x_encoded = encoder.fit_transform(MD_x)\n\n# Set random seed\nnp.random.seed(1234)\n\n# Bootstrapping parameters\nn_bootstraps = 100\nk_values = range(2, 9)\nn_rep = 10\n\n# Initialize a list to store bootstrap results\nboot_results = []\n\n# Bootstrap loop\nfor _ in range(n_bootstraps):\n    # Generate bootstrap sample indices with replacement\n    indices = np.random.choice(len(MD_x_encoded), size=len(MD_x_encoded), replace=True)\n    bootstrap_sample = MD_x_encoded[indices]\n\n    # Perform K-means clustering with a chosen number of clusters\n    best_model = None\n    best_score = float('inf')\n    for k in k_values:\n        model = KMeans(n_clusters=k, n_init=n_rep, random_state=1234)\n        model.fit(bootstrap_sample)\n        if model.inertia_ < best_score:\n            best_model = model\n            best_score = model.inertia_\n\n    # Store the best model for this bootstrap iteration\n    boot_results.append(best_model)\n\n# Print the results\nfor i, model in enumerate(boot_results):\n    print(f\"Bootstrap {i+1} - Number of Clusters: {model.n_clusters}\")\n\n# Note: You can analyze the results further as needed.\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}